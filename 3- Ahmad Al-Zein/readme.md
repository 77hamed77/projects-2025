````markdown
# المساعد الصوتي الشخصي (Hands-Free)

يهدف هذا المشروع إلى إنشاء مساعد صوتي شخصي متعدد الميزات يعمل بدون استخدام اليدين (Hands-Free)، ويستجيب للأوامر الصوتية باللغة العربية. يمكن للمساعد إجراء مهام متنوعة مثل تشغيل التطبيقات، البحث على الويب ويوتيوب، الحصول على معلومات الطقس والوقت، والتحكم في مستوى الصوت، بالإضافة إلى القدرة على الإجابة على استفسارات المعرفة العامة باستخدام نموذج Gemini AI.

## الميزات

* **التحكم الصوتي الكامل**: يستجيب لكلمة تفعيل "أليكسا" لبدء المحادثة، مما يتيح تجربة استخدام بدون لمس.
* **تشغيل التطبيقات**: القدرة على فتح تطبيقات النظام الشائعة (مثل الرسام، الآلة الحاسبة، المفكرة، المنبه، فيجوال ستوديو كود، جوجل كروم).
* **البحث على الويب ويوتيوب**: البحث عن معلومات على جوجل أو مقاطع فيديو على يوتيوب مباشرةً من خلال الأوامر الصوتية.
* **معلومات الطقس**: الحصول على حالة الطقس لمدينتك الافتراضية أو لأي مدينة تحددها.
* **التحكم في الصوت**: رفع، خفض، كتم، أو ضبط مستوى الصوت بنسبة مئوية محددة.
* **معرفة الوقت**: إخبارك بالوقت الحالي.
* **استجابات ذكية (Gemini AI)**: استخدام نموذج Gemini AI للإجابة على أسئلة المعرفة العامة والاستفسارات المعقدة.
* **إعدادات قابلة للتخصيص**: إمكانية تغيير اسم المستخدم، المدينة الافتراضية للطقس، واختيار الميكروفون من خلال واجهة رسومية.
* **واجهة رسومية بسيطة**: عرض تفاعلات المحادثة وحالة المساعد في واجهة مستخدم رسومية (GUI).
* **نظام الإضافات (Plugins)**: بنية معيارية تسمح بإضافة وظائف جديدة بسهولة عبر إضافات Python.
* **تسجيل الأخطاء (Logging)**: نظام تسجيل مفصل يساعد في تتبع الأخطاء وتشخيص المشكلات.

## البنية الأساسية

يتكون المشروع من عدة ملفات Python رئيسية ومجلد للإضافات:

* `main.py`: نقطة الدخول الرئيسية للتطبيق. يقوم بتهيئة نظام التسجيل، وتحميل متغيرات البيئة، وتشغيل الواجهة الرسومية (GUI).
* `gui.py`: يمثل الواجهة الرسومية للمساعد الصوتي. يتعامل مع عرض المحادثات، إدارة الإعدادات، وربط الأوامر الصوتية بالوظائف الخلفية. كما يقوم بتحميل الإضافات ويتفاعل مع نموذج NLU وواجهة Gemini AI.
* `audio_manager.py`: يدير جميع الجوانب المتعلقة بالصوت:
    * `AudioPlaybackThread`: لتشغيل الردود الصوتية وإدارة الملفات الصوتية المؤقتة.
    * `WakeWordThread`: للاستماع إلى كلمة التفعيل ("أليكسا") باستخدام Picovoice.
    * `ConversationThread`: لإدارة وضع المحادثة، والتعرف على الكلام (باستخدام Google Speech Recognition)، وإرسال الأوامر للمعالجة.
* `plugins/`: مجلد يحتوي على الإضافات (Plugins) التي تضيف وظائف محددة للمساعد. كل ملف في هذا المجلد يمثل إضافة يمكنها التعرف على كلمات مفتاحية محددة وتنفيذ مهام معينة.

## الإضافات (Plugins)

يحتوي مجلد `plugins/` على الإضافات التالية:

* `alarm_plugin.py`: يفتح تطبيق المنبهات والساعة على نظام التشغيل الحالي.
* `browser_plugin.py`: يفتح المتصفح الافتراضي أو يبحث عن استعلام محدد على جوجل.
* `time_plugin.py`: يعرض الوقت الحالي.
* `volume_plugin.py`: يتحكم في مستوى صوت النظام (رفع، خفض، كتم).
* `vscode_plugin.py`: يفتح محرر Visual Studio Code.
* `weather_plugin.py`: يجلب معلومات الطقس لمدينة محددة باستخدام WeatherAPI.
* `youtube_plugin.py`: يفتح موقع يوتيوب أو يبحث عن فيديو محدد عليه.

## الإعداد (Setup)

لإعداد وتشغيل المساعد الصوتي، اتبع الخطوات التالية:

### 1. المتطلبات الأساسية

* **Python**: تأكد من تثبيت Python 3.8 أو أحدث.
* **مفتاح API لـ Picovoice**: تحتاج إلى [مفتاح وصول Picovoice (Access Key)](https://console.picovoice.ai/account) لتشغيل ميزة كلمة التفعيل.
* **مفتاح API لـ Google Gemini**: تحتاج إلى [مفتاح API لـ Gemini](https://ai.google.dev/gemini-api/docs/api-key) للتفاعل مع نموذج الذكاء الاصطناعي.
* **مفتاح API لـ WeatherAPI**: تحتاج إلى [مفتاح API لـ WeatherAPI](https://www.weatherapi.com/) للحصول على بيانات الطقس.

### 2. تثبيت المكتبات المطلوبة

افتح الطرفية (Terminal) في مجلد المشروع وقم بتثبيت جميع المتطلبات باستخدام `pip`:

```bash
pip install -r requirements.txt
````

### 3\. إعداد متغيرات البيئة

قم بإنشاء ملف باسم `.env` في الدليل الجذر للمشروع (بجانب `main.py`) وأضف مفاتيح API الخاصة بك كالتالي:

```
PICOVOICE_ACCESS_KEY='أدخل-مفتاح-Picovoice-هنا'
GEMINI_API_KEY='أدخل-مفتاح-Gemini-هنا'
WEATHER_API_KEY='أدخل-مفتاح-WeatherAPI-هنا'
```

### 4\. تدريب نموذج فهم اللغة الطبيعية (NLU)

المشروع يستخدم نموذج NLU مخصصًا لفهم الأوامر. قم بتدريب النموذج عن طريق تشغيل الملف التالي:

```bash
python train_nlu.py
```

هذا سيقوم بإنشاء مجلد `nlu_model_ar` الذي يحتوي على النموذج المدرب.

### 5\. إعداد Pygame (اختياري، للتشغيل الصوتي الأولي)

يتطلب Pygame بعض المكتبات الأساسية لتشغيل الصوت.

  * **في Windows**: عادةً ما يتم تضمين كل ما يلزم مع التثبيت.

  * **في Linux**: قد تحتاج إلى تثبيت مكتبات الصوت، مثل `libsdl2-mixer-2.0-0`.

    ```bash
    sudo apt-get install libsdl2-mixer-2.0-0
    ```

  * **في macOS**:

    ```bash
    brew install sdl2_mixer
    ```

## الاستخدام (Usage)

بعد إكمال خطوات الإعداد، يمكنك تشغيل المساعد الصوتي:

```bash
python main.py
```

عند التشغيل لأول مرة، سيطلب منك المساعد إعداد اسمك، مدينتك الافتراضية، واختيار الميكروفون. بعد ذلك، سيستمع المساعد إلى كلمة التفعيل "أليكسا". بمجرد سماع الكلمة، سيبدأ وضع المحادثة، ويمكنك حينها إعطاء الأوامر الصوتية.

يمكنك أيضًا فتح الإعدادات في أي وقت من خلال زر الترس في الواجهة لتعديل معلوماتك أو تغيير الميكروفون.

## اختبار وظائف المساعد الصوتي

لاختبار وظائف المساعد الصوتي المتعلقة بمهام النظام، والمتصفح، ويوتيوب، و Gemini، يمكنك اتباع الخطوات التالية بعد التأكد من أنك قمت بتعديل ملف `training_data.json` وإعادة تدريب النموذج بنجاح:

**قبل البدء**: تأكد من تشغيل تطبيق المساعد الصوتي الرئيسي (`main.py`) حتى يكون جاهزًا للاستماع للأوامر.

### 1\. اختبار مهام النظام (التحكم بالصوت وفتح التطبيقات)

**أ. التحكم بالصوت:**

  * **رفع الصوت**: قل "ارفع الصوت" أو "علي الصوت".
      * **يجب أن**: يزيد مستوى الصوت، ويقول المساعد "تم رفع الصوت".
  * **خفض الصوت**: قل "اخفض الصوت" أو "وطي الصوت".
      * **يجب أن**: ينخفض مستوى الصوت، ويقول المساعد "تم خفض الصوت".
  * **كتم الصوت**: قل "كتم الصوت".
      * **يجب أن**: يتم كتم الصوت، ويقول المساعد "تم كتم الصوت".
  * **إلغاء كتم الصوت**: قل "إلغاء كتم الصوت" أو "شغل الصوت".
      * **يجب أن**: يعود الصوت، ويقول المساعد "تم تشغيل الصوت".
  * **ضبط مستوى معين**: قل "اضبط الصوت على 50" (أو أي رقم بين 0 و 100).
      * **يجب أن**: يتم ضبط الصوت على المستوى المحدد، ويقول المساعد "تم ضبط الصوت على 50 بالمئة".
  * **معرفة مستوى الصوت الحالي**: قل "صوت" فقط.
      * **يجب أن**: يخبرك المساعد بمستوى الصوت الحالي.

**ب. فتح التطبيقات:**

  * **فتح الرسام**: قل "افتح الرسام" أو "شغل الرسام".
      * **يجب أن**: يفتح تطبيق الرسام.
  * **فتح الآلة الحاسبة**: قل "افتح الآلة الحاسبة" أو "شغل الآلة الحاسبة".
      * **يجب أن**: يفتح تطبيق الآلة الحاسبة.
  * **فتح المفكرة**: قل "افتح المفكرة" أو "شغل المفكرة".
      * **يجب أن**: يفتح تطبيق المفكرة.
  * **فتح جوجل كروم**: قل "افتح جوجل كروم" أو "شغل جوجل كروم".
      * **يجب أن**: يفتح متصفح جوجل كروم.
  * **فتح المنبه**: قل "افتح المنبه" أو "شغل المنبه".
      * **يجب أن**: يفتح تطبيق المنبهات أو الساعة.
  * **فتح فيجوال ستوديو كود**: قل "افتح فيجوال" أو "افتح فيجوال ستوديو كود".
      * **يجب أن**: يفتح برنامج Visual Studio Code.

### 2\. اختبار وظائف المتصفح

  * **فتح المتصفح الافتراضي**: قل "افتح المتصفح".
      * **يجب أن**: يفتح المتصفح الافتراضي على صفحة جوجل الرئيسية.
  * **البحث في المتصفح عن شيء محدد**: قل "ابحث بالمتصفح عن آخر أخبار اليوم" أو "ابحث عن أسعار الذهب".
      * **يجب أن**: يفتح المتصفح ويجري بحثًا عن العبارة المطلوبة على جوجل.

### 3\. اختبار وظائف يوتيوب

  * **فتح يوتيوب**: قل "افتح يوتيوب" أو "شغل يوتيوب".
      * **يجب أن**: يفتح موقع يوتيوب في المتصفح.
  * **البحث في يوتيوب عن فيديو معين**: قل "ابحث في يوتيوب عن اغنيه هادئه" أو "شغل اغنيه هادئه على يوتيوب".
      * **يجب أن**: يفتح يوتيوب ويجري بحثًا عن الفيديو المطلوب.

### 4\. اختبار وظائف Gemini (لأسئلة المعرفة العامة)

**أسئلة المعرفة العامة**: اطرح أسئلة لا تتطلب فتح تطبيق أو بحثًا مباشرًا في المتصفح أو يوتيوب، مثل:

  * "ما هي عاصمه الصين؟"
  * "من هو مخترع الهاتف؟"
  * "كم عدد الكواكب في النظام الشمسي؟"
  * "متى تأسست شركة مايكروسوفت؟"
  * "ما هو لون السماء؟"
  * "من هو مؤسس الدوله؟"

**الاستجابة المتوقعة:**

  * **يجب أن**: يقوم المساعد الصوتي بمعالجة السؤال باستخدام نموذج Gemini (يجب أن ترى "أفكر..." ثم إجابة من "Gemini" في واجهة المستخدم).
  * **يجب ألا**: يفتح أي متصفح أو تطبيق، وألا يرد بالوقت الحالي.

## ملفات البيانات والنموذج

  * `training_data.json`: يحتوي على أمثلة للأوامر وأنواع الكيانات التي يفهمها المساعد. يستخدم لتدريب نموذج NLU.
  * `user_data.json`: يقوم بتخزين بيانات المستخدم مثل الاسم، المدينة الافتراضية، ومؤشر الميكروفون المفضل. يتم إنشاؤه بعد الإعداد الأولي.
  * `nlu_model_ar/`: المجلد الذي يحتوي على نموذج فهم اللغة الطبيعية (NLU) المدرب بواسطة spaCy، والذي يستخدم لتصنيف النوايا واستخراج الكيانات من أوامر المستخدم الصوتية.

## متطلبات النظام

  * **نظام التشغيل**: Windows, macOS, أو Linux.
  * **Python**: الإصدار 3.8 أو أحدث.

<!-- end list -->

```
```